{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05\n",
    "## Part 1: Sampling\n",
    "\n",
    "Welcome to Lab 5! In this lab, we will learn about sampling strategies. More information about sampling in the textbook can be found [here!](https://dukecs.github.io/textbook/chapters/10/sampling-and-empirical-distributions.html)\n",
    "\n",
    "The data used in this lab will contain salary data and statistics for basketball players from the 2014-2015 NBA season. This data was collected from [basketball-reference](http://www.basketball-reference.com) and [spotrac](http://www.spotrac.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "\n",
    "# Don't change this cell; just run it. \n",
    "from gofer.ok import check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dungeons and Dragons and Sampling\n",
    "In the game Dungeons & Dragons, each player plays the role of a fantasy character.\n",
    "\n",
    "A player performs actions by rolling a 20-sided die, adding a \"modifier\" number to the roll, and comparing the total to a threshold for success.  The modifier depends on her character's competence in performing the action.\n",
    "\n",
    "For example, suppose Alice's character, a barbarian warrior named Roga, is trying to knock down a heavy door.  She rolls a 20-sided die, adds a modifier of 11 to the result (because her character is good at knocking down doors), and succeeds if the total is greater than 15.\n",
    "\n",
    "**Question 1.1** <br/>Write code that simulates that procedure.  Compute three values: the result of Alice's roll (`roll_result`), the result of her roll plus Roga's modifier (`modified_result`), and a boolean value indicating whether the action succeeded (`action_succeeded`).  **Do not fill in any of the results manually**; the entire simulation should happen in code.\n",
    "\n",
    "*Hint:* A roll of a 20-sided die is a number chosen uniformly from the array `make_array(1, 2, 3, 4, ..., 20)`.  So a roll of a 20-sided die *plus 11* is a number chosen uniformly from that array, plus 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "possible_rolls = ...\n",
    "roll_result = ...\n",
    "modified_result = ...\n",
    "action_succeeded = ...\n",
    "\n",
    "# The next line just prints out your results in a nice way\n",
    "# once you're done.  You can delete it if you want.\n",
    "print(\"On a modified roll of {:d}, Alice's action {}.\".format(modified_result, \"succeeded\" if action_succeeded else \"failed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br/>Run your cell 7 times to manually estimate the chance that Alice succeeds at this action.  (Don't use math or an extended simulation.). Your answer should be a fraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_success_chance = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we don't know that Roga has a modifier of 11 for this action.  Instead, we observe the modified roll (that is, the die roll plus the modifier of 11) from each of 7 of her attempts to knock down doors.  We would like to estimate her modifier from these 7 numbers.\n",
    "\n",
    "**Question 1.3** <br/>Write a Python function called `simulate_observations`.  It should take no arguments, and it should return an array of 7 numbers.  Each of the numbers should be the modified roll from one simulation.  **Then**, call your function once to compute an array of 7 simulated modified rolls.  Name that array `observations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "modifier = 11\n",
    "num_observations = 7\n",
    "\n",
    "def simulate_observations():\n",
    "    \"\"\"Produces an array of 7 simulated modified die rolls\"\"\"\n",
    "    ...\n",
    "\n",
    "observations = ...\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** <br/>Draw a histogram to display the *probability distribution* of the modified rolls we might see.\n",
    "\n",
    "Question 1.4 does not have an autograder test, so it will be graded on Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We suggest using these bins.\n",
    "roll_bins = np.arange(1, modifier+2+20, 1)\n",
    "\n",
    "...\n",
    "np.arange(1+modifier, 20+modifier+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your histogram should have values 12 to 31 each with a probability of 5%.\n",
    "\n",
    "Now let's imagine we don't know the modifier and try to estimate it from `observations`.\n",
    "\n",
    "One straightforward (but clearly suboptimal) way to do that is to find the *smallest* total roll, since the smallest roll on a 20-sided die is 1.\n",
    "\n",
    "**Question 1.5** <br/>Using that method, estimate `modifier` from `observations`.  Name your estimate `min_estimate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_estimate = ...\n",
    "min_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to estimate the modifier involves the mean of `observations`.\n",
    "\n",
    "**Question 1.6** <br/>Figure out a good estimate based on that quantity.  \n",
    "\n",
    "**Then**, write a function named `mean_based_estimator` that computes your estimate.  It should take an array of modified rolls (like the array `observations`) as its argument and return an estimate of `modifier` based on those numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_based_estimator(nums):\n",
    "    \"\"\"Estimate the roll modifier based on observed modified rolls in the array nums.\"\"\"\n",
    "    ...\n",
    "\n",
    "# Here is an example call to your function.  It computes an estimate\n",
    "# of the modifier from our 7 observations.\n",
    "mean_based_estimate = mean_based_estimator(observations)\n",
    "mean_based_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling Basketball Data\n",
    "\n",
    "Run the cell below to load the player and salary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data = Table().read_table(\"player_data.csv\")\n",
    "salary_data = Table().read_table(\"salary_data.csv\")\n",
    "full_data = salary_data.join(\"PlayerName\", player_data, \"Name\")\n",
    "# The show method immediately displays the contents of a table. \n",
    "# This way, we can display the top of two tables using a single cell.\n",
    "player_data.show(3)\n",
    "salary_data.show(3)\n",
    "full_data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than getting data on every player, imagine that we had gotten data on only a smaller subset of the players.  For 492 players, it's not so unreasonable to expect to see all the data, but usually we aren't so lucky.  Instead, we often make *statistical inferences* about a large underlying population using a smaller sample.\n",
    "\n",
    "A statistical inference is a statement about some statistic of the underlying population, such as \"the average salary of NBA players in 2014 was $3\".  You may have heard the word \"inference\" used in other contexts.  It's important to keep in mind that statistical inferences, unlike, say, logical inferences, can be wrong.\n",
    "\n",
    "A general strategy for inference using samples is to estimate statistics of the population by computing the same statistics on a sample.  This strategy sometimes works well and sometimes doesn't.  The degree to which it gives us useful answers depends on several factors, and we'll touch lightly on a few of those today.\n",
    "\n",
    "One very important factor in the utility of samples is how they were gathered.  We have prepared some example sample datasets to simulate inference from different kinds of samples for the NBA player dataset.  Later we'll ask you to create your own samples to see how they behave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save typing and increase the clarity of your code, we will package the loading and analysis code into two functions. This will be useful in the rest of the lab as we will repeatedly need to create histograms and collect summary statistics from that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1**. <br/>Complete the `histograms` function, which takes a table with columns `Age` and `Salary` and draws a histogram for each one. Use the min and max functions to pick the bin boundaries so that all data appears for any table passed to your function. Use the same bin widths as before (1 year for `Age` and $1,000,000 for `Salary`).\n",
    "\n",
    "*Hint*: When creating the bins for the the histograms, think critically about what the stop argument should be for `np.arange`. Histograms are inclusive on the left hand side of the interval, but not the right. So, if we have a maximum age of 80, we need a 80-81 bin in order to capture this in the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms(t):\n",
    "    ages = t.column('Age')\n",
    "    salaries = t.column('Salary')\n",
    "    age_bins = ...\n",
    "    salary_bins = ...\n",
    "    t.hist('Age', bins=age_bins, unit='year')\n",
    "    t.hist('Salary', bins=salary_bins, unit='$')\n",
    "    return age_bins # Keep this statement so that your work can be checked\n",
    "    \n",
    "histograms(full_data)\n",
    "print('Two histograms should be displayed below')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q2_1.py') # Warning: Charts will be displayed while running this test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2**. <br/>Create a function called `compute_statistics` that takes a Table containing ages and salaries and:\n",
    "- Draws a histogram of ages\n",
    "- Draws a histogram of salaries\n",
    "- Returns a two-element array containing the average age and average salary\n",
    "\n",
    "You can call your `histograms` function to draw the histograms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(age_and_salary_data):\n",
    "    ...\n",
    "    age = ...\n",
    "    salary = ...\n",
    "    ...\n",
    "    \n",
    "\n",
    "full_stats = compute_statistics(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q2_2.py') # Warning: Charts will be displayed while running this test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience sampling\n",
    "One sampling methodology, which is **generally a bad idea**, is to choose players who are somehow convenient to sample.  For example, you might choose players from one team that's near your house, since it's easier to survey them.  This is called, somewhat pejoratively, *convenience sampling*.\n",
    "\n",
    "Suppose you survey only *relatively new* players with ages less than 22.  (The more experienced players didn't bother to answer your surveys about their salaries.)\n",
    "\n",
    "**Question 2.3**  <br/>Assign `convenience_sample_data` to a subset of `full_data` that contains only the rows for players under the age of 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convenience_sample = ...\n",
    "convenience_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q2_3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br/>Assign `convenience_stats` to a list of the average age and average salary of your convenience sample, using the `compute_statistics` function.  Since they're computed on a sample, these are called *sample averages*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convenience_stats = ...\n",
    "convenience_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q2_4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compare the convenience sample salaries with the full data salaries in a single histogram. To do that, we'll need to use the `bin_column` option of the `hist` method, which indicates that all columns are counts of the bins in a particular column. The following cell should not require any changes; just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_salaries(first, second, first_title, second_title):\n",
    "    \"\"\"Compare the salaries in two tables.\"\"\"\n",
    "    max_salary = max(np.append(first.column('Salary'), second.column('Salary')))\n",
    "    bins = np.arange(0, max_salary+1e6+1, 1e6)\n",
    "    first_binned = first.bin('Salary', bins=bins).relabeled(1, first_title)\n",
    "    second_binned = second.bin('Salary', bins=bins).relabeled(1, second_title)\n",
    "    first_binned.join('bin', second_binned).hist(bin_column='bin')\n",
    "\n",
    "compare_salaries(full_data, convenience_sample, 'All Players', 'Convenience Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple random sampling\n",
    "A more principled approach is to sample uniformly at random from the players.  If we ensure that each player is selected at most once, this is a *simple random sample without replacement*, sometimes abbreviated to \"simple random sample\" or \"SRSWOR\".  Imagine writing down each player's name on a card, putting the cards in an urn, and shuffling the urn.  Then, pull out cards one by one and set them aside, stopping when the specified *sample size* is reached.\n",
    "\n",
    "We've produced two samples of the `salary_data` table in this way: `small_srswor_salary.csv` and `large_srswor_salary.csv` contain, respectively, a sample of size 44 (the same as the convenience sample) and a larger sample of size 100.  \n",
    "\n",
    "The `load_data` function below loads a salary table and joins it with `player_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(salary_file):\n",
    "    return player_data.join('Name', Table.read_table(salary_file), 'PlayerName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br/>Run the same analyses on the small and large samples that you previously ran on the full dataset and on the convenience sample.  Compare the accuracy of the estimates of the population statistics that we get from the convenience sample, the small simple random sample, and the large simple random sample.  (Just notice this for yourself -- the autograder will check your sample statistics but will not validate whatever you do to compare.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original:\n",
    "small_srswor_data = ...\n",
    "small_stats = ...\n",
    "large_srswor_data = ...\n",
    "large_stats = ...\n",
    "print('Full data stats:                 ', full_stats)\n",
    "print('Small simple random sample stats:', small_stats)\n",
    "print('Large simple random sample stats:', large_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('part1_tests/q2_5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing simple random samples\n",
    "Often it's useful to take random samples even when we have a larger dataset available. Another is to help us understand how inaccurate other samples are.\n",
    "\n",
    "Tables provide the method `sample()` for producing random samples.  Note that its default is to sample with replacement. To see how to call `sample()`, search the documentation on the [datascience documentation](http://data8.org/datascience/) of the course website, or enter `full_data.sample?` into a code cell and press Shift + Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** <br/>\n",
    "Produce a simple random sample of size 44 from `full_data`.  (You don't need to bother with a join this time -- just use `full_data.sample(...)` directly.  That will have the same result as sampling from `salary_data` and joining with `player_data`.)  Run your analysis on it again and think about these following questions.\n",
    "- Are your results roughly similar to those in the small sample we provided you?  Run your code several times to get new samples.  \n",
    "- How much does the average age change across samples? \n",
    "- What about average salary?\n",
    "\n",
    "Question 2.6 does not have an autograder test, so it is not graded and not in the overall lab grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_small_srswor_data = ...\n",
    "my_small_stats = ...\n",
    "my_small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the results are similar, but not the same, to the sample we were given. The average age tends to stay around the same value as there is a limited range of ages for NBA players, but the salary changes by a sizeable factor due to larger variability in salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7** <br/>As in the previous question, analyze several simple random samples of size 100 from `full_data`.  \n",
    "- Do the histogram statistics seem to change more or less across samples of 100 than across samples of size 44?  \n",
    "- Are the sample averages and histograms closer to their true values for age or for salary?  What did you expect to see?\n",
    "\n",
    "Please fill out your answers in the cell provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_large_srswor_data = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average and histogram statistics seem to change less across samples of this size. They are closer to their true values, which is what we'd expect to see because we are sampling a larger subset of the population. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**(Write your answer here, replacing the content in this cell)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Inference and Capital Punishment\n",
    "\n",
    "Welcome to Part 2! Over the following questions, you will investigate the data relevant to a hotly debated social issue: the possible influence of capital punishment (the death penalty) on murder rates in the United States.\n",
    "\n",
    "By the end of these questions, some of which will appear in next week's lab, you should know how to:\n",
    "\n",
    "1. Test whether observed data appears to be a random sample from a distribution.\n",
    "2. Analyze a natural experiment.\n",
    "3. Implement and interpret a sign test.\n",
    "4. Create a function to run a general hypothesis test.\n",
    "5. Analyze visualizations and draw conclusions from them.\n",
    "\n",
    "**Advice.** Develop your answers incrementally. To perform a complicated table manipulation, break it up into steps, perform each step on a different line, give a new name to each result, and check that each intermediate result is what you expect by displaying it. You can add additional names or functions to the provided cells in order to organize your work. \n",
    "\n",
    "To get started, load `datascience`, `numpy`, `plots`, and `gofer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "\n",
    "from gofer.ok import check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Punishment for crime has many [philosophical justifications](http://plato.stanford.edu/entries/punishment/#ThePun).  An important one is that fear of punishment may *deter* people from committing crimes.\n",
    "\n",
    "In the United States, some jurisdictions execute some people who are convicted of particularly serious crimes, such as murder.  This punishment is called the *death penalty* or *capital punishment*.  The death penalty is controversial, and deterrence has been one focal point of the debate.  There are other reasons to support or oppose the death penalty, but in this project we'll focus on deterrence.\n",
    "\n",
    "The key question about deterrence is: Does instituting a death penalty as a punishment for murder actually reduce the number of murders?\n",
    "\n",
    "You might have a strong intuition in one direction, but the evidence turns out to be surprisingly complex.  Different sides have variously argued that the death penalty has no deterrent effect and that each execution prevents 8 murders, all using statistical arguments!  We'll try to come to our own conclusion.\n",
    "\n",
    "Here is a road map for this part:\n",
    "\n",
    "1. In section 1, we'll visualize and explore the main dataset we'll be using.\n",
    "2. In section 2, we'll test a hypothesis.\n",
    "\n",
    "#### Data\n",
    "\n",
    "The main data source for this project comes from a [paper](http://cjlf.org/deathpenalty/DezRubShepDeterFinal.pdf) by three researchers, Dezhbakhsh, Rubin, and Shepherd.  The dataset contains rates of various violent crimes for every year 1960-2003 (44 years) in every US state.  The researchers compiled the data from the FBI's Uniform Crime Reports.\n",
    "\n",
    "Since crimes are committed by people, not states, we need to account for the number of people in each state when we're looking at state-level data.  Murder rates are calculated as follows:\n",
    "\n",
    "$$\\text{murder rate for state X in year Y} = \\frac{\\text{number of murders in state X in year Y}}{\\text{population in state X in year Y}}*100000$$\n",
    "\n",
    "(Murder is rare, so we multiply by 100,000 just to avoid dealing with tiny numbers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "murder_rates = Table.read_table('crime_rates.csv').select('State', 'Year', 'Population', 'Murder Rate')\n",
    "murder_rates.set_format(\"Population\", NumberFormatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Murder rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `murder_rates` table isn't enough to demonstrate an *association* between crimes and punishments. We would like to check for an association between murder rates and the existence of capital punishment, for each pair of a state and a year.\n",
    "\n",
    "**Question 1.1.** <br/>What additional information will we need before we can check for that association? Assign `extra_info` to a Python list (i.e. [#] or [#, #, ...]) containing the number(s) for all of the additional facts below that we *require* in order to check for association.\n",
    "\n",
    "1) What year(s) the death penalty was introduced in each state (if any).\n",
    "\n",
    "2) Day to day data about when murders occurred.\n",
    "\n",
    "3) What year(s) the death penalty was abolished in each state (if any).\n",
    "\n",
    "4) Rates of other crimes in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"part2_tests/q1_1.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Murder rates vary over time, and different states exhibit different trends. The rates in some states change dramatically from year to year, while others are quite stable. Let's plot the murder rate trends for a few states, just to see the variety.\n",
    "\n",
    "**Question 1.2.** <br/>Draw a line plot with years on the horizontal axis and murder rates on the \n",
    "vertical axis. Include two lines: one for Alaska murder rates and one for Minnesota murder rates. Create this plot using a single call, `ak_mn.plot('Year')`.\n",
    "\n",
    "*Hint*: To create two lines, you will need create the table `ak_mn` with two columns of murder rates, in addition to a column of years. This table will have the following structure:\n",
    "\n",
    "| Year | Murder rate in Alaska | Murder rate in Minnesota |\n",
    "|------|-----------------------|--------------------------|\n",
    "| 1960 | 10.2                  | 1.2                      |\n",
    "| 1961 | 11.5                  | 1                        |\n",
    "| 1962 | 4.5                   | 0.9                      |\n",
    "\n",
    "<center>... (41 rows omitted)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next lines are provided for you.  They create a table\n",
    "# containing only the Alaska information and one containing\n",
    "# only the Minnesota information.\n",
    "ak = murder_rates.where('State', 'Alaska').drop('State', 'Population').relabeled(1, 'Murder rate in Alaska')\n",
    "mn = murder_rates.where('State', 'Minnesota').drop('State', 'Population').relabeled(1, 'Murder rate in Minnesota')\n",
    "\n",
    "# Fill in this line to make a table like the one pictured above.\n",
    "ak_mn = ...\n",
    "ak_mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw your line plot here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"part2_tests/q1_2.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the murder rates of other states? Say, for example, California and New York? Fill in the cell below to plot the murder rates of different pairs of states. **Note:** this should use similar code to question 1.2, with only the variable names changed. The cell below will not be graded, but it creates a cool interactive module!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the murder rates of any two states by filling in the blanks below\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def state(state1, state2):\n",
    "    state1_table = murder_rates.where('State', state1).drop('State', 'Population').relabeled(1, 'Murder rate in {}'.format(state1))\n",
    "    state2_table = murder_rates.where('State', state2).drop('State', 'Population').relabeled(1, 'Murder rate in {}'.format(state2))\n",
    "    s1_s2 = ...\n",
    "    s1_s2.plot('Year')\n",
    "    plots.show()\n",
    "\n",
    "states_array = murder_rates.group('State').column('State')\n",
    "\n",
    "_ = interact(state,\n",
    "             state1=widgets.Dropdown(options=list(states_array),value='California'),\n",
    "             state2=widgets.Dropdown(options=list(states_array),value='New York')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** <br/>Implement the function `most_murderous`, which takes a year (an integer) as its argument. It does two things:\n",
    "1. It draws a horizontal bar chart of the 5 states that had the highest murder rates in that year.\n",
    "2. It returns an array of the names of these states in order of *increasing* murder rate.\n",
    "\n",
    "Assume that the argument is a year in `murder_rates`. You do not need to check that it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "manual_problem_id": "murder_rates_3"
   },
   "outputs": [],
   "source": [
    "def most_murderous(year):\n",
    "    # Assign most to a table of the most murderous states this year in ascending order.\n",
    "    data_for_year = ...\n",
    "    sorted_data = ...\n",
    "    top_5 = ...\n",
    "    top_5.barh('State', 'Murder Rate')\n",
    "    return top_5.column('State')\n",
    "\n",
    "most_murderous(1990) # California, Mississippi, ..., "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you run this cell, several bar charts will be displayed. You can ignore them.\n",
    "check(\"part2_tests/q1_3.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** <br/>How many more people were murdered in California in 1988 than in 1975? Assign `ca_change` to the answer.\n",
    "\n",
    "*Hint*: Make sure you understand how murder rate is calculated. Recall the formula given at the beginning of the project:\n",
    "\n",
    "$$\\text{murder rate for state X in year Y} = \\frac{\\text{number of murders in state X in year Y}}{\\text{population in state X in year Y}}*100000$$\n",
    "\n",
    "Feel free to define new variables and use additional lines to compute your answer. However, **make sure not to change any existing variable names**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "ca = murder_rates.where('State', are.equal_to('California'))\n",
    "ca_change = ...\n",
    "np.round(ca_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part2_tests/q1_4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Changes in Murder Rates\n",
    "\n",
    "In this section, we'll see how to test this null hypothesis: \"For a set of U.S. states, the murder rate was equally likely to go up or down each year.\"\n",
    "\n",
    "Murder rates vary widely across states and years, presumably due to the vast array of differences among states and across US history. Rather than attempting to analyze rates themselves, here we will restrict our analysis to whether or not murder rates increased or decreased over certain time spans. **We will not concern ourselves with how much rates increased or decreased; only the direction of the changes** - whether they increased or decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.diff` function takes an array of values and computes the differences between adjacent items of a list or array as such:\n",
    "\n",
    "    [item 1 - item 0 , item 2 - item 1 , item 3 - item 2, ...]\n",
    "\n",
    "Instead, we may wish to compute the difference between items that are two positions apart. For example, given a 5-element array, we may want:\n",
    "\n",
    "    [item 2 - item 0 , item 3 - item 1 , item 4 - item 2]\n",
    "    \n",
    "The `diff_n` function below computes this result. Don't worry if the implementation uses unfamiliar features of Python, as long as you understand its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_n(values, n):\n",
    "    return np.array(values)[n:] - np.array(values)[:-n]\n",
    "\n",
    "diff_n(make_array(1, 10, 100, 1000, 10000), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** <br/>Implement the function `two_year_changes` that takes an array of murder rates for a state, ordered by increasing year. For all two-year periods (e.g., from 1960 to 1962), it computes and returns **the number of increases minus the number of decreases.**\n",
    "\n",
    "For example, the array `r = make_array(10, 7, 12, 9, 13, 9, 11)` contains 3 increases (10 to 12, 7 to 9, and 12 to 13), 1 decrease (13 to 11), and 1 change that is neither an increase or decrease (9 to 9). Therefore, `two_year_changes(r)` would return 2, the difference between 3 increases and 1 decrease.\n",
    "\n",
    "*Hint*: Consider using the `diff_n` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_year_changes(rates):\n",
    "    \"Return the number of increases minus the number of decreases after two years.\"\n",
    "    ...\n",
    "\n",
    "print('Alaska:',    two_year_changes(ak.column('Murder rate in Alaska')))\n",
    "print('Minnesota:', two_year_changes(mn.column('Murder rate in Minnesota')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"part2_tests/q2_1.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `two_year_changes` to summarize whether rates are mostly increasing or decreasing over time for some state or group of states. Let's see how it varies across the 50 US states.\n",
    "\n",
    "**Question 2.2.** <br/>Assign `changes_by_state` to a table with one row per state that has two columns: the `State` name and the `Murder Rate two_year_changes` statistic computed across all years in our data set for that state.  Its first 2 rows should look like this:\n",
    "\n",
    "|State|Murder Rate two_year_changes|\n",
    "|-|-|\n",
    "|Alabama|-6|\n",
    "|Alaska|-5||\n",
    "\n",
    "<center>... (48 rows omitted)</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_by_state = ...\n",
    "changes_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a histogram of the two-year changes for the states.\n",
    "# Since there are 50 states, each state contributes 2% to one bar.\n",
    "changes_by_state.hist(\"Murder Rate two_year_changes\", bins=np.arange(-11, 19, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"part2_tests/q2_2.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some states have more increases than decreases (a positive change), while some have more decreases than increases (a negative change). \n",
    "\n",
    "**Question 2.3.** <br/>Assign `total_changes` to the total increases minus the total decreases for all two-year periods and all states in our data set. For example, if the murder rate in Ohio went up 23 times and fell 17 times, the total change for Ohio would be 6. We want the total value for all the states together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_changes = ...\n",
    "print('Total increases minus total decreases, across all states and years:', total_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"part2_tests/q2_3.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"More increases than decreases,\" one person exclaims, \"Murder rates tend to go up across two-year periods. What dire times we live in.\"\n",
    "\n",
    "\"Not so fast,\" another person replies, \"Even if murder rates just moved up and down uniformly at random, there would be some difference between the increases and decreases. There were a lot of states and a lot of years, so there were many chances for changes to happen. If state murder rates increase and decrease at random with equal probability, perhaps this difference was simply due to chance!\"\n",
    "\n",
    "**Question 2.4.** <br/>What is the total number of distinct pairs of a state and a two-year period? Assign `num_changes` to this value.\n",
    "\n",
    "For example, Alaska during 1968 to 1970 would count as one distinct pair. Considering all states and all possible two-year periods, how many such pairs are there in total? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_changes = ...\n",
    "num_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"part2_tests/q2_4.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have enough information to perform a hypothesis test.\n",
    "\n",
    "> **Null Hypothesis**: State murder rates increase and decrease over two-year periods as if \n",
    "\"increase\" or \"decrease\" were sampled at random from a uniform distribution, like a fair coin flip.\n",
    "\n",
    "Murder rates can be more likely to go up or more likely to go down. Since we observed 45 more increases than decreases for all two year periods in our dataset, we formulate an alternative hypothesis in accordance with our suspicion:\n",
    "\n",
    "> **Alternative Hypothesis**: State murder rates are more likely to increase over two-year periods.\n",
    "\n",
    "If we had observed more decreases than increases, our alternative hypothesis would have been defined accordingly (that state murder rates are more likely to *decrease*). This is typical in statistical testing - we first observe a trend in the data and then run a hypothesis test to confirm or reject that trend.\n",
    "\n",
    "*Technical note*: These changes in murder rates are not random samples from any population. They describe all murders in all states over all recent years. However, we can imagine that history could have been different, and that the observed changes are the values observed in only one possible world: the one that happened to occur. In this sense, we can evaluate whether the observed \"total increases minus total decreases\" is consistent with a hypothesis that increases and decreases are drawn at random from a uniform distribution.\n",
    "\n",
    "*Important requirements for our test statistic:* We want to choose a test statistic for which large positive values are evidence in favor of the alternative hypothesis, and other values are evidence in favor of the null hypothesis. This is because once we've determined the direction of our alternative hypothesis, we only care about the tail in that direction. If, for example, our p-value cutoff was 5%, we'd check to see if our observed test statistic fell within the largest 5% of values in our null hypothesis distribution. \n",
    "\n",
    "Our test statistic should depend only on whether murder rates increased or decreased, not on the size of any change. Thus we choose:\n",
    "\n",
    "> **Test Statistic**: The number of increases minus the number of decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below samples increases and decreases at random from a uniform distribution 100 times. The final column of the resulting table gives the number of increases and decreases that resulted from sampling in this way. **Using `sample_from_distribution` is faster than using `sample` followed by `group` to compute the same result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = Table().with_columns(\n",
    "    \"Change\", make_array('Increase', 'Decrease'),\n",
    "    \"Chance\", make_array(0.5,        0.5))\n",
    "uniform.sample_from_distribution('Chance', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** <br/>Complete the simulation below, which samples `num_changes` increases/decreases at random many times and forms an empirical distribution of your test statistic under the null hypothesis.  Your job is to\n",
    "* fill in the function `simulate_under_null`, which simulates a single sample under the null hypothesis, and\n",
    "* fill in its argument when it's called below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student",
    "manual_problem_id": "changes_in_murder_rates_5"
   },
   "outputs": [],
   "source": [
    "def simulate_under_null(num_chances_to_change):\n",
    "    \"\"\"Simulates some number changing several times, with an equal\n",
    "    chance to increase or decrease.  Returns the value of our\n",
    "    test statistic for these simulated changes.\n",
    "    \n",
    "    num_chances_to_change is the number of times the number changes.\n",
    "    \"\"\"\n",
    "    sample = ...\n",
    "    return ...\n",
    "\n",
    "uniform_samples = make_array()\n",
    "for i in np.arange(5000):\n",
    "    uniform_samples = np.append(uniform_samples, simulate_under_null(...))\n",
    "\n",
    "simulated_changes = Table().with_column('Test statistic under null', uniform_samples)\n",
    "simulated_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to visualize the empirical distribution of \n",
    "# the test statistic under the null hypothesis.\n",
    "simulated_changes.hist(0, bins=np.arange(-100, 400+25, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6.** Looking at this histogram, draw a conclusion about whether murder rates basically increase as often as they decrease. (Remember that we're only concerned with the *postive direction* because it supports our alternative hypothesis.) You **do not** need to compute a P-value for this question.\n",
    "\n",
    "First, set `which_side` to `\"Right\"` or `\"Left\"` depending on which side of the histogram you need to look at to make your conclusion. \n",
    "\n",
    "Then, set `reject_null` to `True` if rates increase more than they decrease, and we can reject the null hypothesis. Set `reject_null` to `False` if the observed difference is typical under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_side = ...\n",
    "reject_null = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"part2_tests/q2_6.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're finished with the lab! We'll pick off from here next week to finish our investigation of capital punishment in the United States.\n",
    "\n",
    "In order to successfully submit your assignment, follow these steps...\n",
    "- **Save and checkpoint** your lab.\n",
    "- **Run all the tests and verify that they all pass** (the next cell has a shortcut for that), \n",
    "- **Review the notebook one last time** If you make any changes, please **Save and Checkpoint** again.\n",
    "- Hit `File->Download As->PDF via LaTeX` and submit the PDF to gradescope for those questions that were not autograded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import grade_notebook\n",
    "if not globals().get('__GOFER_GRADER__', False):\n",
    "    display(grade_notebook('Week5.ipynb', sorted(glob.glob('part*_tests/q*.py'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "course": "8x",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "lab": "lab02",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "section": "2"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
