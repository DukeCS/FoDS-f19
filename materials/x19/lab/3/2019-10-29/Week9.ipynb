{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 09:\n",
    "## Part 1: Variance of Sample Means and Correlation\n",
    "\n",
    "Welcome to Lab 9!\n",
    "\n",
    "In this lab we will learn about [the variance of sample means](https://www.inferentialthinking.com/chapters/14/5/variability-of-the-sample-mean.html) as well as ways to understand and quantify [the association between two variables](https://www.inferentialthinking.com/chapters/15/1/correlation.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "from gofer.ok import check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. How Faithful is Old Faithful? \n",
    "\n",
    "(Note: clever title comes from [here](http://web.pdx.edu/~jfreder/M212/oldfaithful.pdf).)\n",
    "\n",
    "Old Faithful is a geyser in Yellowstone National Park in the central United States.  It's famous for erupting on a fairly regular schedule.  You can see a video below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For the curious: this is how to display a YouTube video in a\n",
    "# Jupyter notebook.  The argument to YouTubeVideo is the part\n",
    "# of the URL (called a \"query parameter\") that identifies the\n",
    "# video.  For example, the full URL for this video is:\n",
    "#   https://www.youtube.com/watch?v=wE8NDuzt8eg\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"wE8NDuzt8eg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some of Old Faithful's eruptions last longer than others.  When it has a long eruption, there's generally a longer wait until the next eruption.\n",
    "\n",
    "If you visit Yellowstone, you might want to predict when the next eruption will happen, so you can see the rest of the park and come to see the geyser when it erupts.  To predict one variable from another, the first step is to understand the association between them.\n",
    "\n",
    "The dataset has one row for each observed eruption.  It includes the following columns:\n",
    "- **duration**: Eruption duration, in minutes\n",
    "- **wait**: Time between this eruption and the next, also in minutes\n",
    "\n",
    "Run the next cell to load the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "faithful = Table.read_table(\"faithful.csv\")\n",
    "faithful"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 1.1**\n",
    "<br/>\n",
    "Make a scatter plot of the data.  It's conventional to put the column we will try to predict on the vertical axis and the other column on the horizontal axis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look at the scatter plot. Does the association between wait times and eruption durations appear to be linear? \n",
    "\n",
    "There's more going on than just a linear association. The eruption durations seem to cluster; there are a bunch of short eruptions and a bunch of longer ones.  Within each of the clusters, these values appear to be roughly linearly correlated, but perhaps with a different correlation coefficient.\n",
    "\n",
    "The overall relationship is positive, which means that longer eruptions have longer waiting times. Even when the association is more nuanced than a simple linear association, we can still compute the correlation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we'll plot the data in standard units.  Recall that, if `nums` is an array of numbers, then\n",
    "\n",
    "    (nums - np.mean(nums)) / np.std(nums)\n",
    "\n",
    "is an array of those numbers in standard units."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 1.2**\n",
    "<br/>\n",
    "Compute the mean and standard deviation of the eruption durations and waiting times.  **Then** create a table called `faithful_standard` containing the eruption durations and waiting times in standard units.  (The columns should be named `\"duration (standard units)\"` and `\"wait (standard units)\"`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duration_mean = ...\n",
    "duration_std = ...\n",
    "wait_mean = ...\n",
    "wait_std = ...\n",
    "\n",
    "faithful_standard = Table().with_columns(\n",
    "    \"duration (standard units)\", ...,\n",
    "    \"wait (standard units)\", ...)\n",
    "faithful_standard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part1_tests/q1_2.py')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 1.3**\n",
    "<br/>\n",
    "Plot the data again, but this time in standard units."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You'll notice that this plot looks exactly the same as the last one!  The data really are different and the axes are scaled differently.  (The method `scatter` scales the axes so the data fill up the available space.)  So it's important to read the ticks on the axes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 1.4**\n",
    "Among the following numbers, which would you guess is closest to the correlation between eruption duration and waiting time in this dataset?\n",
    "\n",
    "* -1\n",
    "* 0\n",
    "* 1\n",
    "\n",
    "Assign your answer to `closest_correlation`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "closest_correlation = ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part1_tests/q1_4.py')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 1.5**\n",
    "<br/>\n",
    "Compute the correlation `r`.  *Hint:* Use `faithful_standard`.  Section [15.1](https://www.inferentialthinking.com/chapters/15/1/correlation.html) explains how to do this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r = ...\n",
    "r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part1_tests/q1_5.py')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Variability of the Sample Mean\n",
    "\n",
    "By the Central Limit Theorem, the probability distribution of the mean of a large random sample is roughly normal. The bell curve is centered at the population mean. Some of the sample means are higher, and some lower, but the deviations from the population mean are roughly symmetric on either side, as we have seen repeatedly. Formally, probability theory shows that the sample mean is an unbiased estimate of the population mean.\n",
    "\n",
    "In our simulations, we also noticed that the means of larger samples tend to be more tightly clustered around the population mean than means of smaller samples. In this section, we will quantify the variability of the sample mean and develop a relation between the variability and the sample size.\n",
    "\n",
    "Let's take a look at the salaries of employees of the City of San Francisco in 2014. The mean salary reported by the city government was about $75,463.92."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "salaries = Table.read_table('sf_salaries_2014.csv').select(\"salary\")\n",
    "salaries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "salary_mean = np.mean(salaries.column('salary'))\n",
    "salary_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "salaries.hist('salary', bins=np.arange(0, 300000+10000*2, 10000))\n",
    "plots.scatter(salary_mean, 0, marker='^', color='red', s=100);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 2.1**\n",
    "<br/>\n",
    "Clearly, the population does not follow a normal distribution. Keep that in mind as we progress through these exercises.\n",
    "\n",
    "Let's take random samples and look at the probability distribution of the sample mean. As usual, we will use simulation to get an empirical approximation to this distribution.\n",
    "\n",
    "We will define a function `simulate_sample_mean` to do this, because we are going to vary the sample size later. The arguments are the name of the table, the label of the column containing the variable, the sample size, and the number of simulations.\n",
    "\n",
    "Complete the function `simulate_sample_mean`. It will not be graded, but if you haven't implemented it correctly, the rest of the lab won't work properly, so this step is crucial."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Empirical distribution of random sample means\"\"\"\n",
    "\n",
    "def simulate_sample_mean(table, label, sample_size, repetitions):\n",
    "    \n",
    "    means = []\n",
    "\n",
    "    for i in np.arange(repetitions):\n",
    "        new_sample = ...\n",
    "        new_sample_mean = ...\n",
    "        ...\n",
    "\n",
    "    sample_means = Table().with_column('Sample Means', means)\n",
    "    \n",
    "    # Display empirical histogram and print all relevant quantities – don't change this!\n",
    "    sample_means.hist(bins=20)\n",
    "    plots.xlabel('Sample Means')\n",
    "    plots.title('Sample Size ' + str(sample_size))\n",
    "    print(\"Sample size: \", sample_size)\n",
    "    print(\"Population mean:\", np.mean(table.column(label)))\n",
    "    print(\"Average of sample means: \", np.mean(means))\n",
    "    print(\"Population SD:\", np.std(table.column(label)))\n",
    "    print(\"SD of sample means:\", np.std(means))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 2.2**\n",
    "<br/>\n",
    "In the following cell, we will create a sample of size 100 from the salaries table and graph it using our new `simulate_sample_mean` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 10000) \n",
    "plots.xlim(50000, 100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following two cells, simulate the mean of a random sample of 400 salaries and 625 salaries, respectively. In each case, perform 10,000 repetitions of each of these processes. Don't worry about the `plots.xlim` line – it just makes sure that all of the plots have the same x-axis. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulate_sample_mean(..., ..., ..., ...)\n",
    "plots.xlim(50000, 100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulate_sample_mean(..., ..., ..., ...)\n",
    "plots.xlim(50000, 100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the Central Limit Theorem in action – the histograms of the sample means are roughly normal, even though the histogram of the salaries themselves is far from normal.\n",
    "\n",
    "We can also see that each of the three histograms of the sample means is centered very close to the population mean. In each case, the \"average of sample means\" is very close to the population mean. Both values are provided in the printout above each histogram. As expected, the sample mean is an unbiased estimate of the population mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 2.3**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assign the variable `bootstrap_sampled_SD` to the integer corresponding to your answer to the following question:\n",
    "\n",
    "When I increase the number of bootstrap samples that I take, for a fixed sample size, the SD of my sample mean will...\n",
    "\n",
    "1. Increase\n",
    "2. Decrease\n",
    "3. Stay about the same\n",
    "4. Vary widly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bootstrap_sampled_SD = ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part1_tests/q2_3.py')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, we'll look at what happens when we take a fixed sample, then bootstrap from it with different numbers of resamples. How does the distribution of the resampled means change?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 500)\n",
    "plots.xlim(50000, 100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 1000)\n",
    "plots.xlim(50000, 100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 5000)\n",
    "plots.xlim(50000, 100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 10000)\n",
    "plots.xlim(50000, 100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What did you notice about the sample means of the four bootstrapped samples above?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 2.4**\n",
    "<br/>\n",
    "Next, let's think about how the relationships between population SD, sample SD, and SD of sample means change with varying sample size. Which of the following is true? Again, assign the variable `pop_vs_sample` to the integer corresponding to your answer. To gain some intuition, you can run the simulation cells below.\n",
    "\n",
    "1. Sample SD gets smaller with increasing sample size, SD of sample means gets smaller with increasing sample size\n",
    "2. Sample SD gets larger with increasing sample size, SD of sample means stays the same with increasing sample size\n",
    "3. Sample SD becomes more consistent with population SD with increasing sample size, SD of sample means gets smaller with increasing sample size\n",
    "4. Sample SD becomes more consistent with populatoin SD with increasing sample size, SD of smaple means stays the same with increasing sample size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_vs_sample = ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part1_tests/q2_4.py')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see what happens: First, we calculate the population SD so that we can compare the SD of each sample to the SD of the population."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_sd = np.std(salaries.column(\"salary\"))\n",
    "pop_sd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's then see how a small sample behaves. Run the following cells multiple times to see how the SD of the sample changes from sample to sample. Adjust the bins as necessary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_10 = salaries.sample(10)\n",
    "sample_10.hist(\"salary\")\n",
    "print(\"Sample SD: \", np.std(sample_10.column(\"salary\")))\n",
    "simulate_sample_mean(sample_10, 'salary', 10, 1000)\n",
    "plots.xlim(5,120000)\n",
    "plots.ylim(0, .0001);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_200 = salaries.sample(200)\n",
    "sample_200.hist(\"salary\")\n",
    "print(\"Sample SD: \", np.std(sample_200.column(\"salary\")))\n",
    "simulate_sample_mean(sample_200, 'salary', 200, 1000)\n",
    "plots.xlim(5,100000)\n",
    "plots.ylim(0, .00015);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_1000 = salaries.sample(1000)\n",
    "sample_1000.hist(\"salary\")\n",
    "print(\"Sample SD: \", np.std(sample_1000.column(\"salary\")))\n",
    "simulate_sample_mean(sample_1000, 'salary', 1000, 1000)\n",
    "plots.xlim(5,100000)\n",
    "plots.ylim(0, .00025);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's illustrate this trend. Below, you will see how the average absolute error of SD from the population changes with sample size (N)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Don't change this cell, just run it!\n",
    "sample_n_errors = make_array()\n",
    "for i in np.arange(10, 200, 10):\n",
    "    sample_n_errors = np.append(sample_n_errors, np.average([abs(np.std(salaries.sample(i).column(\"salary\"))-pop_sd)\n",
    "                                                             for d in np.arange(100)]))\n",
    "Table().with_column(\"Average absolute error in SD\", sample_n_errors).with_column(\"N\", np.arange(10, 200, 10)).plot(\"N\", \"Average absolute error in SD\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next cell shows how the SD of the sample means changes relative to the sample size (N)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Don't change this cell, just run it!\n",
    "def sample_means(sample_size):\n",
    "    means = make_array()\n",
    "    for i in np.arange(1000):\n",
    "        sample = salaries.sample(sample_size).column('salary')\n",
    "        means = np.append(means, np.mean(sample))\n",
    "    return np.std(means)\n",
    "\n",
    "sample_mean_SDs = make_array()\n",
    "for i in np.arange(50, 1000, 100):\n",
    "    sample_mean_SDs = np.append(sample_mean_SDs, sample_means(i))\n",
    "Table().with_columns(\"SD of sample means\", sample_mean_SDs, \"N\", np.arange(50, 1000, 100))\\\n",
    ".plot(\"N\", \"SD of sample means\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should notice that the distribution of means gets narrower and spikier, and that the distribution of the sample increasingly looks like the distribution of the population as we get to larger sample sizes. \n",
    "\n",
    "**Question 2.7.** Is there a relationship between the sample size and absolute error in standard deviation? What about the sample size and the standard deviation of the sample mean? Assign `q2_7` to the number corresponding to the statements that answer these two questions.\n",
    "\n",
    "1. The average absolute error in SD decreases roughly linearly with sample size. The SD of the sample means is inversely proportional to the square root of sample size.\n",
    "2. The average absolute error in SD decreases roughly linearly with sample size. The SD of the sample means is directly proportional to the square root of sample size.\n",
    "3. The average absolute error in SD decreases roughly exponentially with sample size. The SD of the sample means is inversely proportional to the square root of sample size.\n",
    "4. The average absolute error in SD decreases roughly exponentially with sample size. The SD of the sample means is directly proportional to the square root of sample size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q2_7 = ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part1_tests/q2_7.py')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Central Limit Theorem"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading**: \n",
    "* [Why the mean matters](https://www.inferentialthinking.com/chapters/14/why-the-mean-matters.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. The Bootstrap and The Normal Curve\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise, we will explore a dataset that includes the safety inspection scores for restaurants in the city of Austin, Texas.  We will be interested in determining the average restaurant score for the city from a random sample of the scores; the average restaurant score is out of 100. We'll compare two methods for computing a confidence interval for that quantity: the bootstrap resampling method, and an approximation based on the Central Limit Theorem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "pop_restaurants = Table.read_table('restaurant_inspection_scores.csv').drop(5,6)\n",
    "pop_restaurants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question 1\n",
    "Plot a histogram of the scores in the cell below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the **population mean**:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_mean = np.mean(pop_restaurants.column(3))\n",
    "pop_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Often it is impossible to find complete datasets like this.  Imagine we instead had access only to a random sample of 100 restaurant inspections, called `restaurant_sample`.  That table is created below. We are interested in using this sample to estimate the population mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "restaurant_sample = pop_restaurants.sample(100, with_replacement=False)\n",
    "restaurant_sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question 2 \n",
    "Plot a histogram of the **sample** scores in the cell below. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write your code here:\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the **sample mean**:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question 3\n",
    "Complete the function `bootstrap_scores` below. It should take no arguments. It should simulate drawing 5000 resamples from `restaurant_sample` and computing the mean restaurant score in each resample.  It should return an array of those 5000 resample means."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def bootstrap_scores():\n",
    "    resampled_means = ...\n",
    "    for i in range(5000):\n",
    "        resampled_mean = ...\n",
    "        resampled_means = ...\n",
    "    ...\n",
    "\n",
    "resampled_means = bootstrap_scores()\n",
    "resampled_means"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part2_tests/q1_3.py')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take a look at the histogram of the **resampled means**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Table().with_column('Resampled Means', resampled_means).hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question 4\n",
    "Compute a 95 percent confidence interval for the average restaurant score using the array `resampled_means`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "print(\"95% confidence interval for the average restaurant score, computed by bootstrapping:\\n(\",lower_bound, \",\", upper_bound, \")\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question 5\n",
    "Does the distribution of the resampled mean scores look normally distributed? State \"yes\" or \"no\" and describe in one sentence why you would expect that result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Write your answer here, replacing this text.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question 6\n",
    "Does the distribution of the **sampled scores** look normally distributed? State \"yes\" or \"no\" and describe in one sentence why you should expect this result.\n",
    "\n",
    "**Hint:** Remember that we are no longer talking about the resampled means!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Write your answer here, replacing this text.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the last question, you'll need to recall two facts.\n",
    "1. If a group of numbers has a normal distribution, around 95% of them lie within 2 standard deviations of their mean.\n",
    "2. The Central Limit Theorem tells us the quantitative relationship between the following:\n",
    "    * the standard deviation of an array of numbers.\n",
    "    * the standard deviation of an array of means of samples taken from those numbers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question 7\n",
    "Without referencing the array `resampled_means` or performing any new simulations, calculate an interval around the `sample_mean` that covers approximately 95% of the numbers in the `resampled_means` array.  **You may use the following values to compute your result, but you should not perform additional resampling** - think about how you can use the CLT to accomplish this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_sd = np.std(restaurant_sample.column(3))\n",
    "sample_size = restaurant_sample.num_rows\n",
    "\n",
    "lower_bound_normal = ...\n",
    "upper_bound_normal = ...\n",
    "print(\"95% confidence interval for the average restaurant score, computed by a normal approximation:\\n(\",lower_bound_normal, \",\", upper_bound_normal, \")\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This confidence interval should look very similar to the one you computed in **Question 4**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Testing the Central Limit Theorem\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the **sum** or **average** of a large random sample drawn with replacement will be roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that the standard deviation of this normal distribution is given by \n",
    "\n",
    "$$\\frac{\\texttt{sd of the original distribution}}{\\sqrt{\\texttt{sample size}}}$$ \n",
    "\n",
    "In other words, suppose we start with *any distribution* that has standard deviation $x$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the **mean** of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{x}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class, but in this exercise, we will be exploring some data to see the CLT in action."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 1.** The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as sample size goes up.\n",
    "\n",
    "Consider a coin flip. If we say `Heads` is $1$ and `Tails` is $0$, then there's a 50% chance of getting a 1 and a 50% chance of getting a 0, which definitely doesn't match our definition of a normal distribution.  The average of several coin tosses, where Heads is 1 and Tails is 0, is equal to the proportion of heads in those coin tosses (which is equivalent to the mean value of the coin tosses), so the CLT should hold **true** if we compute the sample proportion of heads many times.\n",
    "\n",
    "Write a function called `sample_size_n` that takes in a sample size $n$. It should return an array that contains 5000 sample proportions of heads, each from $n$ coin flips."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_size_n(n):\n",
    "    coin_proportions = make_array(.5, .5) # our coin is fair\n",
    "    heads_proportions = make_array()\n",
    "    for i in np.arange(5000):\n",
    "        simulated_proportions = ...\n",
    "        prop_heads = ...\n",
    "        heads_proportions = ...\n",
    "    return heads_proportions\n",
    "\n",
    "\n",
    "sample_size_n(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "The code below will use the function you just defined to plot the empirical distribution of the sample mean for various sample sizes. Drag the slider or click on the number to the right to type in a sample size of your choice. The x- and y-scales are kept the same to facilitate comparisons. Notice the shape of the graph as the sample size increases and decreases."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "from ipywidgets import interact\n",
    "\n",
    "def outer(f):\n",
    "    def graph(x):\n",
    "        bins = np.arange(-0.01,1.05,0.02)\n",
    "        sample_props = f(x)\n",
    "        Table().with_column('Sample Size: {}'.format(x), sample_props).hist(bins=bins)\n",
    "        plots.ylim(0, 30)\n",
    "        print('Sample SD:', np.std(sample_props))\n",
    "        plots.show()\n",
    "    return graph\n",
    "    \n",
    "interact(outer(sample_size_n), x=(0, 400, 1), continuous_update=False);\n",
    "\n",
    "# Min sample size is 0, max is 400\n",
    "# The graph will refresh a few times when you drag the slider around"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that even the means of samples of 10 items follow a roughly bell-shaped distribution.  A sample of 50 items looks quite bell-shaped."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 2:** In the plot for a sample size of 10, why are the bars spaced at intervals of .1, with gaps in between?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Write your answer here, replacing this text.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "Now we will test the second claim of the CLT: That the SD of the sample mean is the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "We have imported the flight delay data and computed its standard deviation for you."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "united = Table.read_table('united_summer2015.csv')\n",
    "united_std = np.std(united.column('Delay'))\n",
    "united_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 3:** Write a function called `empirical_sample_mean_sd` that takes a sample size `n` as its argument. The function should simulate 500 samples with replacement of size `n` from the flight delays dataset, and it should return the standard deviation of the **means of those 500 samples**.\n",
    "\n",
    "*Hint:* This function will be similar to the `sample_size_n` function you wrote earlier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def empirical_sample_mean_sd(n):\n",
    "    sample_means = make_array()\n",
    "    for i in np.arange(500):\n",
    "        sample = ...\n",
    "        sample_mean = ...\n",
    "        sample_means = ...\n",
    "    return np.std(sample_means)\n",
    "\n",
    "empirical_sample_mean_sd(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part2_tests/q2_3.py')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question 4:** Now, write a function called `predict_sample_mean_sd` to find the predicted value of the standard deviation of means according to the relationship between the standard deviation of the sample mean and sample size that is discussed [here](https://www.inferentialthinking.com/chapters/14/5/variability-of-the-sample-mean.html) in the textbook. It takes a sample size `n` (a number) as its argument.  It returns the predicted value of the standard deviation of the mean delay time for samples of size `n` from the flight delays (represented in the table `united`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_sample_mean_sd(n):\n",
    "    ...\n",
    "\n",
    "predict_sample_mean_sd(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check('part2_tests/q2_4.py')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "The cell below will plot the predicted and empirical SDs for the delay data for various sample sizes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sd_table = Table().with_column('Sample Size', np.arange(1,101))\n",
    "predicted = sd_table.apply(predict_sample_mean_sd, 'Sample Size')\n",
    "empirical = sd_table.apply(empirical_sample_mean_sd, 'Sample Size')\n",
    "sd_table = sd_table.with_columns('Predicted SD', predicted, 'Empirical SD', empirical)\n",
    "sd_table.scatter('Sample Size')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 5:** Do our predicted and empirical values match? Why is this the case?\n",
    "\n",
    "**Hint:** Are there any laws that we learned about in class that might help explain this?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Write your answer here, replacing this text.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Submission\n",
    "\n",
    "Congratulations, you're done with Lab 09!  Be sure to \n",
    "- **IMPORTANT** Before you do anything, **Save and Checkpoint** from the `File` menu. Please do this first before running the cell below,\n",
    "- **run all the tests and verify that they all pass** (the next cell has a shortcut for that), \n",
    "- **Review the notebook one last time** If you make any changes, please **Save and Checkpoint** again.\n",
    "- Hit `File->Download As->PDF via LaTeX` and submit the PDF to gradescope for those questions that were not autograded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import grade_notebook\n",
    "if not globals().get('__GOFER_GRADER__', False):\n",
    "    display(grade_notebook('Week9.ipynb', sorted(glob.glob('part*_tests/q*.py'))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "assignment": "hw09",
  "course": "8x",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "lab": "lab01",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "section": "3",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}