{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Regression Inference\n",
    "\n",
    "## Part 1\n",
    "\n",
    "Sometimes, the primary purpose of regression analysis is to learn something about the slope or intercept of the best-fitting line.  When we use a sample of data to estimate the slope or intercept, our estimate is subject to random error, just as in the simpler case of the mean of a random sample.\n",
    "\n",
    "In this lab, we'll use regression to get an accurate estimate for the age of the universe, using pictures of exploding stars.  Our estimate will come from a sample of all exploding stars. We'll compute a confidence interval to quantify the error caused by sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "from matplotlib import patches\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# These lines load the tests.\n",
    "from gofer.ok import check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Age of the Universe\n",
    "\n",
    "### The Actual Big Bang Theory\n",
    "In the early 20th century, the most popular cosmological theory suggested that the universe had always existed at a fixed size.  Today, the Big Bang theory prevails: Our universe started out very small and is still expanding.\n",
    "\n",
    "A consequence of this is Hubble's Law, which states that every celestial object that's reasonably far away from Earth (for example, another galaxy) is moving away from us at a constant speed.  If we extrapolate that motion backwards to the time when everything in the universe was in the same place, that time is (roughly) the beginning of the universe!\n",
    "\n",
    "Scientists have used this fact, along with measurements of the current *location* and *movement speed* of other celestial objects, to estimate when the universe started.\n",
    "\n",
    "The cell below simulates a universe in which our sun is the center and every other star is moving away from us.  Each star starts at the same place as the sun, then moves away from it over time.  Different stars have different directions *and speeds*; the arrows indicate the direction and speed of travel.\n",
    "\n",
    "Run the cell, then move the slider to see how things change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.  (The simulation is actually not\n",
    "# that complicated; it just takes a lot of code to draw\n",
    "# everything.  So you don't need to read this unless you\n",
    "# have time and are curious about more advanced plotting.)\n",
    "\n",
    "num_locations = 15\n",
    "example_velocities = Table().with_columns(\n",
    "    \"x\", np.random.normal(size=num_locations),\n",
    "    \"y\", np.random.normal(size=num_locations))\n",
    "start_of_time = -2\n",
    "\n",
    "def scatter_after_time(t, start_of_time, end_of_time, velocities, center_name, other_point_name, make_title):\n",
    "    max_location = 1.1*(end_of_time-start_of_time)*max(max(abs(velocities.column(\"x\"))), max(abs(velocities.column(\"y\"))))\n",
    "    new_locations = velocities.with_columns(\n",
    "            \"x\", (t-start_of_time)*velocities.column(\"x\"),\n",
    "            \"y\", (t-start_of_time)*velocities.column(\"y\"))\n",
    "    plt.scatter(make_array(0), make_array(0), label=center_name, s=100, c=\"yellow\")\n",
    "    plt.scatter(new_locations.column(\"x\"), new_locations.column(\"y\"), label=other_point_name)\n",
    "    for i in np.arange(new_locations.num_rows):\n",
    "        plt.arrow(\n",
    "            new_locations.column(\"x\").item(i),\n",
    "            new_locations.column(\"y\").item(i),\n",
    "            velocities.column(\"x\").item(i),\n",
    "            velocities.column(\"y\").item(i),\n",
    "            fc='black',\n",
    "            ec='black',\n",
    "            head_width=0.025*max_location,\n",
    "            lw=.15)\n",
    "    plt.xlim(-max_location, max_location)\n",
    "    plt.ylim(-max_location, max_location)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.gca().set_position(make_array(0, 0, 1, 1))\n",
    "    plt.legend(bbox_to_anchor=(1.6, .7))\n",
    "    plt.title(make_title(t))\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    scatter_after_time,\n",
    "    t=widgets.FloatSlider(min=start_of_time, max=5, step=.05, value=0, msg_throttle=1),\n",
    "    start_of_time=fixed(start_of_time),\n",
    "    end_of_time=fixed(5),\n",
    "    velocities=fixed(example_velocities),\n",
    "    center_name=fixed(\"our sun\"),\n",
    "    other_point_name=fixed(\"other star\"),\n",
    "    make_title=fixed(lambda t: \"The world {:01g} year{} in the {}\".format(abs(t), \"\" if abs(t) == 1 else \"s\", \"past\" if t < 0 else \"future\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "From the example above, when can you say the simulated universe started? Assign `beginning` to the number corresponding to your answer.\n",
    "\n",
    "1. 2 years ago\n",
    "2. 1 year ago\n",
    "3. 2 years in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "beginning = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check('part1_tests/q1_1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "After 5 years in the simulation, stars with longer arrows are further away from the Sun. Why? Assign `longer` to the number corresponding to your answer.\n",
    "\n",
    "**Note:** 5 years corresponds to the slider being placed all the way to the right.\n",
    "\n",
    "1. The length of the arrows represents each star's direction of movement. So stars in a certain direction tend to be farther away from the sun.\n",
    "2. The length of the arrows represents each star's speed.  So stars with longer arrows are moving faster away from the Sun.\n",
    "3. The length of the arrows represents each star's speed. So stars with longer arrows are moving slower away from the Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "longer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check('part1_tests/q1_2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy: driving\n",
    "Here's an analogy to illustrate how scientists use information about stars to estimate the age of the universe.\n",
    "\n",
    "Suppose that at some point in the past, our friend Mei started driving in a car going at a steady speed of 60 miles per hour straight east.  We're still standing where she started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see a picture of Mei's locations over time.\n",
    "\n",
    "mei_velocity = Table().with_columns(\"x\", make_array(60), \"y\", make_array(0))\n",
    "interact(\n",
    "    scatter_after_time,\n",
    "    t=widgets.FloatSlider(min=-2, max=1, step=.05, value=0, msg_throttle=1),\n",
    "    start_of_time=fixed(-2),\n",
    "    end_of_time=fixed(1),\n",
    "    velocities=fixed(mei_velocity),\n",
    "    center_name=fixed(\"Us\"),\n",
    "    other_point_name=fixed(\"Mei\"),\n",
    "    make_title=fixed(lambda t: \"Mei's position {:01g} hour{} in the {}\".format(abs(t), \"\" if abs(t) == 1 else \"s\", \"past\" if t < 0 else \"future\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know how long she's been driving, but we forgot to record the time when she left.  If we find out that she's 120 miles away, and she's been going 60 miles per hour the whole time, we can infer that she left 2 hours ago.\n",
    "\n",
    "One way we can compute that number is by fitting a line to a scatter plot of our locations and speeds.  It turns out that the *slope* of that line is the amount of time that has passed.  Run the next cell to see a picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "small_driving_example = Table().with_columns(\n",
    "        \"Name\",                                       make_array(\"Us\", \"Mei\"),\n",
    "        \"Speed moving away from us (miles per hour)\", make_array(0,    60),\n",
    "        \"Current distance from us (miles)\",           make_array(0,    120))\n",
    "\n",
    "small_driving_example.scatter(1, 2, s=200, fit_line=True)\n",
    "\n",
    "# Fancy magic to draw each person's name with their dot.\n",
    "with_slope_indicator = small_driving_example.with_row(\n",
    "    [\"Slope = 2\\ hours\", small_driving_example.column(1).mean(), small_driving_example.column(2).mean()])\n",
    "for i in range(with_slope_indicator.num_rows):\n",
    "    name = with_slope_indicator.column(0).item(i)\n",
    "    x = with_slope_indicator.column(1).item(i)\n",
    "    y = with_slope_indicator.column(2).item(i)\n",
    "    plt.scatter(make_array(x - 15), make_array(y + 15), s=1000*len(name), marker=\"$\\mathrm{\" + name + \"}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slope of the line is 2 hours.  (The units are vertical-axis units divided by horizontal-axis units, which are $\\frac{\\texttt{miles}}{\\texttt{miles} / \\texttt{hour}}$, or hours.)  So that's our answer.\n",
    "\n",
    "Imagine that you don't know Mei's exact distance or speed, only rough estimates.  Then if you drew this line, you'd get a slightly bad estimate of the time since she left.  But if you measured the distance and speed of hundreds of people who left you at the same time going different speeds, and drew a line through them, the slope of that line would be a pretty good estimate of the time they left, even if the individual measurements weren't exactly right.\n",
    "\n",
    "The `drivers.csv` dataset contains the speeds and distances-from-start of 100 drivers.  They all left the same starting location at the same time, driving at a fixed speed on a straight line away from the start.  The measurements aren't exact, so they don't fit exactly on a line.  We've created a scatter plot and drawn a line through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "Table.read_table(\"drivers.csv\").scatter(0, 1, fit_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "By looking at the fit line, estimate how long ago (in hours) Mei left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the start time you infer from the above line.\n",
    "driving_start_time_hours = ...\n",
    "driving_start_time_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('part1_tests/q1_3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to cosmology\n",
    "To do the same thing for the universe, we need to know the distance-from-Earth and speed-away-from-Earth of many celestial objects.  Using pictures taken by very accurate telescopes and a lot of physics, astronomers have been able to estimate both.  It turns out that *nearby supernovae* -- stars that have recently died and exploded -- are among the best sources of this data, because they are very easy to see.  This picture taken by the Hubble telescope shows an entire galaxy, with a single supernova - as bright by itself as billions of stars - at the bottom left.\n",
    "\n",
    "<img src=\"supernova.jpg\">\n",
    "\n",
    "Our astronomical data for today will come from the [Supernova Cosmology Project](http://supernova.lbl.gov/union/) at Lawrence Berkeley Lab.  The original dataset is [here](http://supernova.lbl.gov/union/figures/SCPUnion2.1_mu_vs_z.txt), with (brief) documentation [here](http://supernova.lbl.gov/union/descriptions.html#Magvsz).  Each row in the table corresponds to a supernova near Earth that was observed by astronomers.  From pictures like the one above, the astronomers deduced how far away each supernova was from Earth and how fast it was moving away from Earth.  Their deductions were good, but not perfect.\n",
    "\n",
    "Run the cell below to load the data into a table called `close_novas` and make a scatter plot. (If you prefer, you can also use the name `close_novae`; both are correct.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "close_novas = Table.read_table(\"close_novas.csv\")\n",
    "close_novae = close_novas\n",
    "\n",
    "close_novas.scatter(0, 1, fit_line=True)\n",
    "close_novas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Looking at this plot, make a guess at the age of the universe.\n",
    "\n",
    "**Note**: Make sure you get the units right!  In case you need to know what a parsec is, it's a big unit of distance, equivalent to 30.86 trillion kilometers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill this in manually by examining the line above.\n",
    "first_guess_universe_age_years = ...\n",
    "\n",
    "# This just shows your guess as a nice string, in billions of years.\n",
    "\"{:,} billion years\".format(round(first_guess_universe_age_years / 1e9, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the line yourself\n",
    "`fit_line=True` is convenient, but we need to be able to calculate the slope as a number.  Recall that the least-squares regression line for our supernova data is:\n",
    "* the line\n",
    "* with the smallest average (over all the supernovae we observe)\n",
    "* error,\n",
    "* squared,\n",
    "* where the error is\n",
    "\n",
    "$$\\text{the supernova's actual distance from Earth} - \\text{the height of the line at that supernova's speed.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "Define a function called `errors`.  It should take three arguments:\n",
    "1. a table like `close_novas` (with the same column names and meanings, but not necessarily the same data)\n",
    "2. the slope of a line (a number)\n",
    "3. the intercept of a line (a number).\n",
    "\n",
    "It should return an array of the errors made when a line with that slope and intercept is used to predict distance from speed for each supernova in the given table.  (The error is the actual distance minus the predicted distance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "def errors(t, slope, intercept):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "Using `errors`, compute the errors for the line with slope `16000` and intercept `0` on the `close_novas` dataset.  Name that array `example_errors`.  Then make a scatter plot of the errors.\n",
    "\n",
    "**Hint:** To make a scatter plot of the errors, plot the error for each supernova in the dataset.  Put the actual speed on the horizontal axis and the error on the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_errors = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that the errors are almost all negative.  That means our line is a little bit too steep.  Let's find a better one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Define a function called `fit_line`.  It should take a table like `close_novas` (with the same column names and meanings) as its argument.  It should return an array containing the slope (as item 0) and intercept (as item 1) of the least-squares regression line predicting distance from speed for that table.\n",
    "\n",
    "Note: If you haven't tried to use the [`minimize` function](http://data8.org/datascience/util.html#datascience.util.minimize) yet, now is a great time to practice. Here's an [example from the textbook](https://www.inferentialthinking.com/chapters/15/3/Method_of_Least_Squares).\n",
    "\n",
    "*Hint*: Define a function `mse` within `fit_line` that takes a slope and intercept as its arguments. `mse` will use the table passed into `fit_line` to compute predicted distances and then return the mean squared error between the predicted and actual distances. Within `fit_line`, you can call `mse` the way you would any other function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(tbl):\n",
    "    # Your code may need more than 1 line below here.\n",
    "    def mse(..., ...):\n",
    "        ... \n",
    "    return ... \n",
    "    \n",
    "# Here is an example call to your function.  To test your function,\n",
    "# figure out the right slope and intercept by hand.\n",
    "example_table = Table().with_columns(\n",
    "    \"Speed (parsecs/year)\", make_array(0, 1),\n",
    "    \"Distance (million parsecs)\", make_array(1, 3))\n",
    "fit_line(example_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_7.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "Use `fit_line` to fit a line to `close_novas`. Assign the output to `best_line`. Assign the first and second elements in `best_line` to `best_line_slope` and `best_line_intercept`, respectively.\n",
    "\n",
    "Then, set `new_errors` equal to the errors that we get calling `errors` with our new line. The cell below will graph the corresponding residual plot with a best fit line.\n",
    "\n",
    "Make sure that the residual plot makes sense (Hint: what qualities should the best fit line of a residual plot have?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_line = ...\n",
    "best_line_slope = ...\n",
    "best_line_intercept = ...\n",
    "\n",
    "new_errors = ...\n",
    "\n",
    "# This code displays the residual plot, given your values for the best_line_slope and best_line_intercept\n",
    "Table().with_columns(\"Speed (parsecs/year)\", \n",
    "                    close_novas.column(\"Speed (parsecs/year)\"), \n",
    "                    \"Distance errors (million parsecs)\", \n",
    "                    new_errors\n",
    "                   ).scatter(0, 1, fit_line=True)\n",
    "\n",
    "# This just shows your answer as a nice string, in billions of years.\n",
    "\"Slope: {:g} (corresponding to an estimated age of {:,} billion years)\".format(best_line_slope, round(best_line_slope/1000, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That slope (multiplied by 1 million) is an estimate of the age of the universe.  The current best estimate of the age of the universe (using slightly more sophisticated techniques) is 13.799 billion years.  Did we get close?\n",
    "\n",
    "One reason our answer might be a little off is that we are using a sample of only some of the supernovae in the universe.  Our sample isn't exactly random, since astronomers presumably chose the novae that were easiest to measure (or used some other nonrandom criteria).  But let's assume it is.  How can we produce a confidence interval for the age of the universe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9\n",
    "It's time to bootstrap so that we can quantify the variability in our estimate! Simulate 1000 resamples from `close_novas`.  For each resample, compute the slope of the least-squares regression line, and multiply it by 1 million to compute an estimate of the age of the universe.  Store these ages in an array called `bootstrap_ages`, and then use them to compute a 95% confidence interval for the age of the universe.\n",
    "\n",
    "**Note:** This might take up to a minute, and more repetitions will take even longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_ages = make_array()\n",
    "for i in np.arange(1000):\n",
    "    bootstrap_ages = ...\n",
    "\n",
    "lower_end = ...\n",
    "upper_end = ...\n",
    "Table().with_column(\"Age estimate\", bootstrap_ages*1e-9).hist(bins=np.arange(12, 16, .1), unit=\"billion years\")\n",
    "print(\"95% confidence interval for the age of the universe: [{:g}, {:g}] billion years\".format(lower_end*1e-9, upper_end*1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('part1_tests/q1_9.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work, data astronomer! You can compare your result to the [Planck project 2015 results](https://arxiv.org/pdf/1502.01589.pdf), which estimated the age of the universe to be 13.799Â±0.021 billion years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: \n",
    "* [Inference for Regression](https://www.inferentialthinking.com/chapters/16/inference-for-regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visual Diagnostics for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model Diagnostics\n",
    "Linear regression isn't always the best way to describe the relationship between two variables. We'd like to develop techniques that will help us decide whether or not to use a linear model to predict one variable based on another.\n",
    "\n",
    "We will use the insight that if a regression fits a set of points well, then the residuals from that regression line will show no pattern when plotted against the predictor variable. \n",
    "\n",
    "The table below contains information about crime rates and median home values in suburbs of Boston. We will attempt to use linear regression to predict median home value in terms of crime rate.\n",
    "\n",
    "#### About the dataset\n",
    "All data are from 1970.  Crime rates are per capita per year; home values are in thousands of dollars.  The crime data come from the FBI, and home values are from the US Census Bureau.  \n",
    "\n",
    "Run the next cell to load the data and see a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = Table.read_table('boston_housing.csv')\n",
    "boston.scatter('Crime Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 1\n",
    "\n",
    "Write a function called `residuals`.  It should take a single argument, a table.  It should first compute the slope and intercept of the regression line that predicts the second column of that table (accessible as `tbl.column(1)`) using the first column (`tbl.column(0)`). The function should return an array containing the *residuals* for that regression line. Recall that residuals are given by \n",
    "\n",
    "$$residual = observed \\ value - regression \\ estimate$$\n",
    "\n",
    "Hint: If your code is getting long, think about how you can split the problem up into multiple smaller, simpler functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "def residuals(tbl):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q1_1.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 2\n",
    "\n",
    "Make a scatter plot of the residuals for the Boston housing dataset against crime rate. Crime rate should be on the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 3\n",
    "\n",
    "Does the plot of residuals look roughly like a formless cloud, or is there some kind of pattern? Are they centered around 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "residual_pattern_1"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 4\n",
    "\n",
    "Does it seem like a linear model is appropriate for describing the relationship between crime and median home value?\n",
    "\n",
    "Assign `linear` to `True` if a linear model is appropriate for describing the relationship, and `False` if it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "linear = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q1_4.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section [15.6](https://www.inferentialthinking.com/chapters/15/6/numerical-diagnostics.html) of the textbook describes some mathematical facts that hold for all regression estimates, regardless of goodness of fit.  One fact is that there is a relationship between the standard deviation of the residuals, the standard deviation of the response variable, and the correlation.  Let us test this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 5\n",
    "\n",
    "Directly compute the standard deviation of the residuals from the Boston data.  Then compute the same quantity without using the residuals, using the formula described in section 15.6 [here](https://www.inferentialthinking.com/chapters/15/6/Numerical_Diagnostics.html#sd-of-the-residuals) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "boston_residual_sd = ...\n",
    "boston_residual_sd_from_formula = ...\n",
    "\n",
    "print(\"Residual SD: {0}\".format(boston_residual_sd))\n",
    "print(\"Residual SD from the formula: {0}\".format(boston_residual_sd_from_formula))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q1_5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding the Least Squares Regression Line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll work with a small invented data set.  Run the next cell to generate the dataset `d` and see a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Table().with_columns(\n",
    "    'x', make_array(0,  1,  2,  3,  4),\n",
    "    'y', make_array(1, .5, -1,  2, -3))\n",
    "d.scatter('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 1 (Ungraded, but you'll need the result later)\n",
    "Running the cell below will generate sliders that control the slope and intercept of a line through the scatter plot.  When you adjust a slider, the line will move.\n",
    "\n",
    "By moving the line around, make your best guess at the least-squares regression line.  (It's okay if your line isn't exactly right, as long as it's reasonable.)\n",
    "\n",
    "**Note:** Python will probably take about a second to redraw the plot each time you adjust the slider.  We suggest clicking the place on the slider you want to try and waiting for the plot to be drawn; dragging the slider handle around will cause a long lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(slope, intercept):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    \n",
    "    endpoints = make_array(-2, 7)\n",
    "    p = plt.plot(endpoints, slope*endpoints + intercept, color='orange', label='Proposed line')\n",
    "    \n",
    "    plt.scatter(d.column('x'), d.column('y'), color='blue', label='Points')\n",
    "    \n",
    "    plt.xlim(-4, 8)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.8, .8))\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_line, slope=widgets.FloatSlider(min=-4, max=4, step=.1), intercept=widgets.FloatSlider(min=-4, max=4, step=.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "You can probably find a reasonable-looking line by just eyeballing it.  But remember: the least-squares regression line minimizes the mean of the squared errors made by the line for each point.  Your eye might not be able to judge squared errors very well.\n",
    "\n",
    "#### A note on mean and total squared error\n",
    "\n",
    "It is common to think of the least-squares line as the line with the least *mean* squared error (or the square root of the mean squared error), as the textbook does.\n",
    "\n",
    "But it turns out that it doesn't matter whether you minimize the mean squared error or the *total* squared error.  You'll get the same best line in either case.\n",
    "\n",
    "That's because the total squared error is just the mean squared error multipled by the number of points (`d.num_rows`).  So if one line gets a better total squared error than another line, then it also gets a better mean squared error.  In particular, the line with the smallest total squared error is also better than every other line in terms of mean squared error.  That makes it the least squares line.\n",
    "\n",
    "**tl; dr:** Minimizing the mean squared error minimizes the total squared error as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 2 (Ungraded, but you'll need the result later)\n",
    "The next cell produces a more useful plot.  Use it to find a line that's closer to the least-squares regression line, keeping the above note in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_and_errors(slope, intercept):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    points = make_array(-2, 7)\n",
    "    p = plt.plot(points, slope*points + intercept, color='orange', label='Proposed line')\n",
    "    ax = p[0].axes\n",
    "    \n",
    "    predicted_ys = slope*d.column('x') + intercept\n",
    "    diffs = predicted_ys - d.column('y')\n",
    "    for i in np.arange(d.num_rows):\n",
    "        x = d.column('x').item(i)\n",
    "        y = d.column('y').item(i)\n",
    "        diff = diffs.item(i)\n",
    "        \n",
    "        if diff > 0:\n",
    "            bottom_left_x = x\n",
    "            bottom_left_y = y\n",
    "        else:\n",
    "            bottom_left_x = x + diff\n",
    "            bottom_left_y = y + diff\n",
    "        \n",
    "        ax.add_patch(patches.Rectangle(make_array(bottom_left_x, bottom_left_y), abs(diff), abs(diff), color='red', alpha=.3, label=('Squared error' if i == 0 else None)))\n",
    "        plt.plot(make_array(x, x), make_array(y, y + diff), color='red', alpha=.6, label=('Error' if i == 0 else None))\n",
    "    \n",
    "    plt.scatter(d.column('x'), d.column('y'), color='blue', label='Points')\n",
    "    \n",
    "    plt.xlim(-4, 8)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.8, .8))\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_line_and_errors, slope=widgets.FloatSlider(min=-4, max=4, step=.1), intercept=widgets.FloatSlider(min=-4, max=4, step=.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Describe the visual criterion you used to find a line in question 2. How did you judge whether one line was better than another? \n",
    "\n",
    "For example, a possible (but incorrect) answer is, \"I tried to make the red line for the bottom-right point as small as possible.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "least_squares_3"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "We can say that a point influences the line by how much the line would move if the point were removed from the data set. Does the outlier at (3, 2) have more or less influence than any other point on the resulting best-fit line? \n",
    "\n",
    "Assign `more_influence` to `True` if the outlier (3,2) has more influence than any other point on the best-fit line, or `False` if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "more_influence = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q2_4.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have Python find this line for us.  When we use `minimize`, Python goes through a process similar to the one you might have used in question 2.\n",
    "\n",
    "But Python can't look at a plot that displays errors!  Instead, we tell it how to find the total squared error for a line with a given slope and intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "Define a function called `total_squared_error`.  It should take two numbers as arguments:\n",
    "\n",
    "1. the slope of some potential line\n",
    "2. the intercept of some potential line\n",
    "\n",
    "It should return the total squared error when we use that line to make predictions for the dataset `d`.\n",
    "\n",
    "Recall that `d` has two columns: _x_ and _y_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def total_squared_error(slope, intercept):\n",
    "    predictions = ...\n",
    "    errors = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q2_5.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "What is the total squared error for the line you found by \"eyeballing\" the errors in Question 1?  What about Question 2, where you made a guess that was \"aided\" by a visualization of the squared error?  (It's okay if the error went up, but for many students, the error will go down when using the visual aid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_problem_id": "least_squares_6"
   },
   "outputs": [],
   "source": [
    "eyeballed_error = ...\n",
    "aided_error = ...\n",
    "print(\"Eyeballed error:\", eyeballed_error, \"\\nAided error:\", aided_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q2_6.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Use `minimize` to find the slope and intercept for the line that minimizes the total squared error. This is the definition of a least-squares regression line. \n",
    "\n",
    "**Note:** `minimize` will return a single array containing the slope as the first element and intercept as the second. Read more of its documentation [here](http://data8.org/datascience/util.html?highlight=minimize#datascience.util.minimize) or an example of its use [here](https://www.inferentialthinking.com/chapters/15/3/method-of-least-squares.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_problem_id": "minimize_slope_intercept"
   },
   "outputs": [],
   "source": [
    "# The staff solution used 1 line of code above here.\n",
    "slope_from_minimize = ...\n",
    "intercept_from_minimize = ...\n",
    "print(\"Least-squares regression line: predicted_y =\",\n",
    "      slope_from_minimize,\n",
    "      \"* x + \",\n",
    "      intercept_from_minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q2_7.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "What is the total squared error for the least-squares regression line that you found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "best_total_squared_error = ...\n",
    "best_total_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q2_8.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the following cell to plot this \"best fit\" line and its errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_and_errors(slope_from_minimize, intercept_from_minimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantifying Sampling Errors in Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, in this class we've used confidence intervals to quantify uncertainty about estimates as well as to test predictions. To run a hypothesis test using a confidence interval, we use the following procedure:\n",
    "1. Formulate a null hypothesis\n",
    "2. Formulate an alternative hypothesis \n",
    "3. Choose a test statistic and compute the observed value for the test statistic\n",
    "4. Bootstrap, finding a value of the test stat for each resample\n",
    "5. Generate a 95% confidence interval from those resampled test stats\n",
    "6. Based on whether your value is in an interval, make a conclusion\n",
    "\n",
    "Another thing we've covered recently is the use of linear regression to make predictions, using correlated variables. An example is, say, predicting the height of children based on the heights of their parents.\n",
    "\n",
    "We can combine these two topics together in order to make even more powerful statements about our population given just a sample as before. We can use the following techniques to do so:\n",
    "- Bootstrapped interval for the true slope\n",
    "- Bootstrapped prediction interval for y (given a particular value of x)\n",
    "\n",
    "This part further explores these two advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the Old Faithful dataset from our lab on regression. The table contains two pieces of information about each eruption of the Old Faithful geyser in Yellowstone National Park:\n",
    "1. The duration of the eruption, in minutes.\n",
    "2. The time between this eruption and the next eruption (the \"waiting time\"), in minutes.\n",
    "\n",
    "The dataset is plotted below along with its line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:50.503658Z",
     "start_time": "2018-04-11T12:05:50.340244Z"
    }
   },
   "outputs": [],
   "source": [
    "faithful = Table.read_table('faithful_inference.csv')\n",
    "faithful.scatter('duration', fit_line=True)\n",
    "faithful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Bootstrap Confidence Interval for the True Slope\n",
    "\n",
    "Last time we looked at this dataset, we noticed the apparent linear relationship between duration and wait, and we decided to use regression to predict wait in terms of duration. However, our data are just a sample of all the eruptions that have happened at Old Faithful. As we know, relationships can appear in a sample that don't really exist in the population from which the sample was taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "Before we move forward using our linear model, we would like to know whether or not there truly exists a relationship between duration and wait time. If there is no relationship between the two, then we'd expect a correlation of 0, which would give us a slope of 0. Now, write in null and alternative hypotheses, based on your knowledge of hypothesis tests you've conducted in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "manual_problem_id": "slope_inference_1"
   },
   "source": [
    "- **Null Hypothesis:** [*Your solution goes here*]\n",
    "- **Alternate Hypothesis:** [*Your solution goes here*]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the method of confidence intervals to test this hypothesis.\n",
    "\n",
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 2\n",
    "\n",
    "We'll warm up by implementing some familiar functions. You may use these functions throughout this assignment. Start by defining these two functions:\n",
    "\n",
    "1. `standard_units` should take in an array of numbers and return an array containing those numbers converted to standard units.\n",
    "2. `correlation` should take in a table with 2 columns and return the correlation between these columns. Hint: you may want to use the `standard_units` function you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:50.894154Z",
     "start_time": "2018-04-11T12:05:50.889145Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def standard_units(arr):\n",
    "    ...\n",
    "\n",
    "def correlation(tbl):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:51.170309Z",
     "start_time": "2018-04-11T12:05:51.019905Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q3_2.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 3\n",
    "\n",
    "Using the functions you just implemented, create a function called `fit_line`.  It should take a table as its argument.  It should return an array containing the slope and intercept of the regression line that predicts the second column in the table using the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:51.332907Z",
     "start_time": "2018-04-11T12:05:51.325888Z"
    },
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "def fit_line(tbl):\n",
    "    ...\n",
    "    slope = ...\n",
    "    intercept = ...\n",
    "    return make_array(slope, intercept)\n",
    "\n",
    "# This should compute the slope and intercept of the regression\n",
    "# line predicting wait time from duration in the faithful dataset.\n",
    "fit_line(faithful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:51.754766Z",
     "start_time": "2018-04-11T12:05:51.624390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure your fit_line function fits a reasonable line \n",
    "# to the data in faithful, using the plot below\n",
    "\n",
    "slope, intercept = fit_line(faithful)\n",
    "faithful.scatter(0)\n",
    "plt.plot([min(faithful[0]), max(faithful[0])], \n",
    "         [slope*min(faithful[0])+intercept, slope*max(faithful[0])+intercept])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:51.916168Z",
     "start_time": "2018-04-11T12:05:51.777799Z"
    },
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q3_3.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the tools we need in order to create a confidence interval quantifying our uncertainty about the true relationship between duration and wait time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 4\n",
    "\n",
    "Use the bootstrap to compute 1000 resamples from our dataset. For each resample, compute the slope of the best fit line. Put these slopes in an array called `resample_slopes`, giving you the empirical distribution of regression line slopes in resamples. Plot a histogram of these slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 5\n",
    "\n",
    "Use your resampled slopes to construct an approximate 95% confidence interval for the true value of the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:53.077324Z",
     "start_time": "2018-04-11T12:05:53.072310Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "lower_end = ...\n",
    "upper_end = ...\n",
    "print(\"95% confidence interval for slope: [{:g}, {:g}]\".format(lower_end, upper_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q3_5.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 6\n",
    "\n",
    "Based on your confidence interval, would you accept or reject the null hypothesis that the true slope is 0?  Why?  What P-value cutoff are you using?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "slope_inference_6"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Bootstrap Prediction Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we're tourists at Yellowstone, and we'd like to know how long we'll have to wait for the next Old Faithful eruption.  We decide to use our regression line to make some predictions for the waiting times.  But just as we're uncertain about the slope of the true regression line, we're also uncertain about the predictions we'd make based on the true regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "*(Questions 7-12 are optional)*\n",
    "#### Question 7\n",
    "\n",
    "Define the function `fitted_value`.  It should take 2 arguments:\n",
    "\n",
    "1. A table with 2 columns.  We'll be predicting the values in the second column using the first.\n",
    "2. A number, the value of the predictor variable for which we'd like to make a prediction.\n",
    "\n",
    "Make sure to use your `fit_line` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:53.768008Z",
     "start_time": "2018-04-11T12:05:53.763999Z"
    },
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "def fitted_value(table, given_x):\n",
    "    # The staff solution took 4 lines of code.\n",
    "    ...\n",
    "\n",
    "# Here's an example of how fitted_value is used.  This should\n",
    "# compute the prediction for the wait time of an eruption that lasts \n",
    "# two minutes .\n",
    "two_minutes_wait = fitted_value(faithful, 2)\n",
    "two_minutes_wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:54.229924Z",
     "start_time": "2018-04-11T12:05:54.093546Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q3_7.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 8\n",
    "\n",
    "The park ranger tells us that the most recent eruption lasted 6 minutes. Using your function above, assign the variable `most_recent_wait` to the predicted wait time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:54.430725Z",
     "start_time": "2018-04-11T12:05:54.424720Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "most_recent_wait = ...\n",
    "most_recent_wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:54.734166Z",
     "start_time": "2018-04-11T12:05:54.591788Z"
    },
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q3_8.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juan, a fellow tourist, raises the following objection to your prediction:\n",
    "\n",
    "> \"Your prediction depends on your sample of 272 eruptions.  Couldn't your prediction have been different if you had happened to have a different sample of eruptions?\"\n",
    "\n",
    "Having read section [16.3](https://www.inferentialthinking.com/chapters/16/3/prediction-intervals.html) of the textbook, you know just the response!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 9\n",
    "\n",
    "Define the function `bootstrap_lines`.  It should take two arguments:\n",
    "1. A table with two columns.  As usual, we'll be predicting the second column using the first.\n",
    "2. An integer, a number of bootstraps to run.\n",
    "\n",
    "It should return a *table* whose first column, `\"Slope\"`, contains the given number of bootstrapped slopes, and whose second column, `\"Intercept\"`, contains the corresponding bootstrapped intercepts.  Each slope and intercept should come from a regression line that predicts column 2 from column 1 of a resample of the given table.  The table should have 1 row for each bootstrap replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:55.090019Z",
     "start_time": "2018-04-11T12:05:55.086009Z"
    },
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "def bootstrap_lines(tbl, num_bootstraps):\n",
    "    ...\n",
    "\n",
    "# When you're done, this code should produce the slopes\n",
    "# and intercepts of 1000 regression lines computed from\n",
    "# resamples of the faithful table.\n",
    "regression_lines = bootstrap_lines(faithful, 1000)\n",
    "regression_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 10\n",
    "\n",
    "Create an array called `predictions_for_six`.  It should contain 1000 numbers.  Each number should be the predicted waiting time after an eruption with a duration of 6 minutes, using a different bootstrapped regression line. Hint: use `regression_lines` from the previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:55.991855Z",
     "start_time": "2018-04-11T12:05:55.759236Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "predictions_for_six = ...\n",
    "\n",
    "# This will make a histogram of your predictions:\n",
    "table_of_predictions = Table().with_column('Predictions at eruptions=6', predictions_for_six)\n",
    "table_of_predictions.hist('Predictions at eruptions=6', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 11\n",
    "\n",
    "Create a 95 percent confidence interval for these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:56.097136Z",
     "start_time": "2018-04-11T12:05:56.089117Z"
    },
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "\n",
    "print('95% Confidence interval for predictions for x=6: (', lower_bound,\",\", upper_bound, ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q3_11.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "#### Question 12\n",
    "\n",
    "Look at the scatter plot of the data at the start of this exercise. \n",
    "Determine which of the following are true, then set `question_12_choice` to an array consisting of the numbers of statements that are true. For example, if you think that 1 and 2 are true but 3 is false, you'd assign `question_12_choice` to be an array consisting of the values 1 and 2.\n",
    "\n",
    "Statement 1: This confidence covers 95 percent of waiting times of eruptions in `faithful` that had an eruption duration of 6 minutes.\n",
    "\n",
    "Statement 2: This interval gives a sense of how much actual wait times differ from your prediction.\n",
    "\n",
    "Statement 3: The confidence interval quantifies our uncertainty in our estimate of what the true regression line would predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:56.479878Z",
     "start_time": "2018-04-11T12:05:56.476869Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "question_12_choice = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:05:56.798444Z",
     "start_time": "2018-04-11T12:05:56.659088Z"
    },
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check('part2_tests/q3_12.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Congratulations, you're done with Lab 11!  Be sure to \n",
    "- **IMPORTANT** Before you do anything, **Save and Checkpoint** from the `File` menu. Please do this first before running the cell below,\n",
    "- **run all the tests and verify that they all pass** (the next cell has a shortcut for that), \n",
    "- **Review the notebook one last time** If you make any changes, please **Save and Checkpoint** again.\n",
    "- Hit `File->Download As->PDF via LaTeX` and submit the PDF to gradescope for those questions that were not autograded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import grade_notebook\n",
    "if not globals().get('__GOFER_GRADER__', False):\n",
    "    display(grade_notebook('Week11.ipynb', sorted(glob.glob('part*_tests/q*.py'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "assignment": "hw11",
  "course": "8x",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "lab": "lab03",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "section": "3",
  "widgets": {
   "state": {
    "6c09ba2474d24e10bdd21db7b9699237": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "ef0a0194fbdd498787d3894efa009a7e": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}